{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d7f261d-bf2e-4998-93a6-c020f3c6ce77",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "183aaed4-3a1e-441f-af6e-502a033ea221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re, hashlib, math, time\n",
    "from random import randint, seed\n",
    "seed(1631996)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cef6fa99-a05b-4043-b497-659c5046379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class hashFamily:\n",
    "    def __init__(self, i):\n",
    "        self.resultSize = 8 # how many bytes we want back\n",
    "        self.maxLen = 20 # how long can our i be (in decimal)\n",
    "        self.salt = str(i).zfill(self.maxLen)[-self.maxLen:]\n",
    "        \n",
    "    def get_hash_value(self, el_to_hash):\n",
    "        return int(hashlib.sha1(str(el_to_hash).encode('utf-8') + self.salt.encode('utf-8')).hexdigest()[-self.resultSize:], 16)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b55136e7-235c-4ad9-9459-5fc6d436fb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class shingler:\n",
    "    def __init__(self, k):\n",
    "        \n",
    "        if k > 0:\n",
    "            self.k = int(k)\n",
    "        else:\n",
    "            self.k = 10\n",
    "        \n",
    "    #inner class utility\n",
    "    def process_doc(self, document):\n",
    "        return re.sub(\"( )+|(\\n)+\",\" \",document).lower()\n",
    "    \n",
    "    '''def get_shingles(self, document):\n",
    "        shingles = set()\n",
    "        document= self.process_doc(document)\n",
    "        for i in range(0, len(document)-self.k+1 ):\n",
    "            shingles.add(document[i:i+self.k])\n",
    "        return shingles'''\n",
    "    \n",
    "    def get_shingles(self, document):\n",
    "        shingles = set()\n",
    "        document = self.process_doc(document)\n",
    "        tokens = document.split()  # Split the document into tokens\n",
    "        for i in range(0, len(tokens) - self.k + 1):\n",
    "            shingle = \" \".join(tokens[i:i + self.k])\n",
    "            shingles.add(shingle)\n",
    "        return shingles\n",
    "    \n",
    "    def get_k(self):\n",
    "        return self.k\n",
    "    \n",
    "    #return sorted hash\n",
    "    def get_hashed_shingles(self, shingles_set):\n",
    "        hash_function = hashFamily(0)\n",
    "        return sorted( {hash_function.get_hash_value(s) for s in shingles_set} )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b394041-0806-4d10-a4ae-0f5b4f2b181a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class minhashSigner:\n",
    "    def __init__(self, sig_size):\n",
    "        self.sig_size=sig_size\n",
    "        self.hash_functions = [hashFamily(randint(0,10000000000)) for i in range(0,sig_size)]\n",
    "    \n",
    "    def compute_set_signature(self, set_):\n",
    "        set_sig = []\n",
    "        for h_funct in self.hash_functions:\n",
    "            min_hash = math.inf\n",
    "            for el in set_:\n",
    "                h = h_funct.get_hash_value(el)\n",
    "                if h < min_hash:\n",
    "                    min_hash = h\n",
    "                \n",
    "            set_sig.append(min_hash)\n",
    "        \n",
    "        return set_sig\n",
    "    \n",
    "    #return a list of lists that can be seen as the signature matrix\n",
    "    def compute_signature_matrix(self, set_list):\n",
    "        signatures = []\n",
    "        #print(len(signatures))\n",
    "        #print(\"----------------------------------------\")\n",
    "        #print(\"set_list: \",len(set_list),set_list)\n",
    "        for s in set_list:\n",
    "            signatures.append( self.compute_set_signature(s) )\n",
    "            \n",
    "        return signatures\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "505892fd-ad68-45b0-85b7-a467544837ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class lsh:\n",
    "    def __init__(self, threshold=0.8):\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def get_signature_matrix_bands(self, sig_matrix, bands_nr, sign_len): \n",
    "        #bands_nr = b\n",
    "        #sign_len = n\n",
    "        r = int(sign_len/bands_nr) #number of rows in each band\n",
    "        bands = {} # {band_nr: [col_1,col_2,...]} where col_1 is all the values of Sig(S_i) for band b.\n",
    "        for i in range(0,bands_nr):\n",
    "            bands[i] = []\n",
    "        \n",
    "        # put Subsets of the columns of signature matrix into the appropriate bucket and cosider a column \n",
    "        # as a unique block so that we can hash the entire column.\n",
    "        # Basically a band is a list of element, where each element is a subset of a signature of a given set.\n",
    "        for signature in sig_matrix: \n",
    "            \n",
    "            for i in range(0, bands_nr):\n",
    "                idx = i*r    \n",
    "                bands[i].append(' '.join(str(x) for x in signature[idx:idx+r]) ) \n",
    "                    \n",
    "        return bands\n",
    "\n",
    "    #band is a list \n",
    "    # construct a dictionary {hash(band_column): doc_id that produced this hash}\n",
    "    def get_band_buckets(self, band, hash_funct):\n",
    "        buckets = {}\n",
    "        for doc_id in range(0,len(band)):\n",
    "            value = hash_funct.get_hash_value( band[doc_id] )\n",
    "            if value not in buckets:\n",
    "                buckets[value] = [doc_id]\n",
    "            else:\n",
    "                 buckets[value].append(doc_id)\n",
    "                \n",
    "        return buckets\n",
    "    \n",
    "    def get_candidates_list(self, buckets):\n",
    "        candidates = set()\n",
    "        # buckets is a dictionary containing key=bucket, value= list of doc_ids that hashed to bucket\n",
    "        for bucket,candidate_list in buckets.items():\n",
    "            if len(candidate_list) > 1:\n",
    "                for i in range(0,len(candidate_list)-1):\n",
    "                    for j in range(i+1,len(candidate_list)):  \n",
    "                        pair = tuple(sorted( (candidate_list[i],candidate_list[j]) ))\n",
    "                        candidates.add(pair)\n",
    "                \n",
    "        return candidates #ie a set of couples, each couple is a candidate pair\n",
    "    \n",
    "    def check_candidates(self, candidates_list, threshold, sigs):\n",
    "        similar_docs = set() #set of tuples\n",
    "        \n",
    "        # similar_pair is a couple containing doc_ids of documents that hashed to same bucket\n",
    "        for  similar_pair in candidates_list:\n",
    "            #for all the pairs of document in the list check similarity of their signatures\n",
    "            doc_id_1 = similar_pair[0]\n",
    "            doc_id_2 = similar_pair[1]\n",
    "            signature_1 = set(sigs[doc_id_1]) #get the i-th column from signature matrix where i is doc_id in the collision list\n",
    "            signature_2 = set(sigs[doc_id_2])\n",
    "            js = len(signature_1.intersection(signature_2)) /len(signature_1.union(signature_2))\n",
    "            \n",
    "            if js >= threshold:\n",
    "                similar_docs.add( tuple(sorted((doc_id_1,doc_id_2) )) )\n",
    "                        \n",
    "        return similar_docs\n",
    "    \n",
    "    def get_similar_items(self, sig_matrix, bands_nr, sign_len):\n",
    "        similar_docs = set()\n",
    "        #divide signature matrix into bands\n",
    "        bands = lsh_instance.get_signature_matrix_bands(sig_matrix,bands_nr,sign_len)\n",
    "        \n",
    "        #for all the bands\n",
    "        for band_id, elements in bands.items():\n",
    "            #produce the buckets for the given band (band_id) with a random hash function\n",
    "            buckets = lsh_instance.get_band_buckets(elements, hash_funct=hashFamily(randint(0,10000000000)))\n",
    "            #Get all the candidate pairs\n",
    "            candidates = lsh_instance.get_candidates_list(buckets)\n",
    "            #Check all candidate pairs' signatures\n",
    "            for sim_tuple in lsh_instance.check_candidates(candidates, self.threshold, sig_matrix):\n",
    "                similar_docs.add( sim_tuple)\n",
    "\n",
    "        return similar_docs #return all the similar signatures that respect the threshold\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "208cd4ee-40a1-4a80-9d49-018aa737c4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>published</th>\n",
       "      <th>body</th>\n",
       "      <th>summary</th>\n",
       "      <th>summary_type</th>\n",
       "      <th>topic</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reuters</td>\n",
       "      <td>43869</td>\n",
       "      <td>Asian Markets</td>\n",
       "      <td>Taiwan seen slipping into recession in Q1, Reu...</td>\n",
       "      <td>2023-04-26T04:54:00</td>\n",
       "      <td>TAIPEI, April 26 (Reuters) - Taiwan's export-d...</td>\n",
       "      <td>* \\n* For poll data click:\\n* Preliminary Q1 G...</td>\n",
       "      <td>BULLETS</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>reuters</td>\n",
       "      <td>43881</td>\n",
       "      <td>Retail &amp; Consumer</td>\n",
       "      <td>Corona beer maker Constellation sees 2024 prof...</td>\n",
       "      <td>2023-04-06T12:59:00</td>\n",
       "      <td>April 6 (Reuters) - Constellation Brands Inc (...</td>\n",
       "      <td></td>\n",
       "      <td>NULL</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>reuters</td>\n",
       "      <td>43904</td>\n",
       "      <td>Mergers &amp; AcquisitionsMergers &amp; AcquisitionsDr...</td>\n",
       "      <td>BioNTech, DualityBio to develop cancer treatme...</td>\n",
       "      <td>2023-04-03T21:28:00</td>\n",
       "      <td>April 3 (Reuters) - Germany's BioNTech (22UAy....</td>\n",
       "      <td></td>\n",
       "      <td>NULL</td>\n",
       "      <td>303</td>\n",
       "      <td>0.708222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reuters</td>\n",
       "      <td>43912</td>\n",
       "      <td>CommentaryBy Rebecca ChristieBreakingviews</td>\n",
       "      <td>New EU debt rules have way to avoid past mistakes</td>\n",
       "      <td>2023-04-04T10:32:00</td>\n",
       "      <td>BRUSSELS, April 4 (Reuters Breakingviews) - Th...</td>\n",
       "      <td></td>\n",
       "      <td>NULL</td>\n",
       "      <td>236</td>\n",
       "      <td>0.126197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reuters</td>\n",
       "      <td>43916</td>\n",
       "      <td>CommentaryBy Rebecca ChristieBreakingviews</td>\n",
       "      <td>Rome foot-dragging can help EU kick bad aid ha...</td>\n",
       "      <td>2023-04-18T09:52:00</td>\n",
       "      <td>BRUSSELS, April 18 (Reuters Breakingviews) - I...</td>\n",
       "      <td></td>\n",
       "      <td>NULL</td>\n",
       "      <td>133</td>\n",
       "      <td>0.225602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    source     id                                           category  \\\n",
       "0  reuters  43869                                      Asian Markets   \n",
       "1  reuters  43881                                  Retail & Consumer   \n",
       "2  reuters  43904  Mergers & AcquisitionsMergers & AcquisitionsDr...   \n",
       "3  reuters  43912         CommentaryBy Rebecca ChristieBreakingviews   \n",
       "4  reuters  43916         CommentaryBy Rebecca ChristieBreakingviews   \n",
       "\n",
       "                                               title            published  \\\n",
       "0  Taiwan seen slipping into recession in Q1, Reu...  2023-04-26T04:54:00   \n",
       "1  Corona beer maker Constellation sees 2024 prof...  2023-04-06T12:59:00   \n",
       "2  BioNTech, DualityBio to develop cancer treatme...  2023-04-03T21:28:00   \n",
       "3  New EU debt rules have way to avoid past mistakes  2023-04-04T10:32:00   \n",
       "4  Rome foot-dragging can help EU kick bad aid ha...  2023-04-18T09:52:00   \n",
       "\n",
       "                                                body  \\\n",
       "0  TAIPEI, April 26 (Reuters) - Taiwan's export-d...   \n",
       "1  April 6 (Reuters) - Constellation Brands Inc (...   \n",
       "2  April 3 (Reuters) - Germany's BioNTech (22UAy....   \n",
       "3  BRUSSELS, April 4 (Reuters Breakingviews) - Th...   \n",
       "4  BRUSSELS, April 18 (Reuters Breakingviews) - I...   \n",
       "\n",
       "                                             summary summary_type  topic  \\\n",
       "0  * \\n* For poll data click:\\n* Preliminary Q1 G...      BULLETS     -1   \n",
       "1                                                            NULL     -1   \n",
       "2                                                            NULL    303   \n",
       "3                                                            NULL    236   \n",
       "4                                                            NULL    133   \n",
       "\n",
       "   probability  \n",
       "0     0.000000  \n",
       "1     0.000000  \n",
       "2     0.708222  \n",
       "3     0.126197  \n",
       "4     0.225602  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_parquet(\"gs://scraped-news-article-data-null/topic-2023-4.parquet\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3432d953-a40d-4f60-b2f4-926ab3168326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14646, 10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "448e1088-27ab-4a9b-9ce9-324c7ddc2c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6436, 10)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicates based on columns 'A', 'B', and 'C'\n",
    "dataset = dataset.drop_duplicates(subset=['source' ,'category','title', 'body']).copy()\n",
    "\n",
    "# Print the DataFrame without duplicates\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84f56f4b-fb9f-418f-9447-71ecac2dc861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index in the dataset_v2 DataFrame\n",
    "dataset.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2adf23d1-ba5e-4093-b6f6-112f89962d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>published</th>\n",
       "      <th>body</th>\n",
       "      <th>summary</th>\n",
       "      <th>summary_type</th>\n",
       "      <th>topic</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reuters</td>\n",
       "      <td>43869</td>\n",
       "      <td>Asian Markets</td>\n",
       "      <td>Taiwan seen slipping into recession in Q1, Reu...</td>\n",
       "      <td>2023-04-26T04:54:00</td>\n",
       "      <td>TAIPEI, April 26 (Reuters) - Taiwan's export-d...</td>\n",
       "      <td>* \\n* For poll data click:\\n* Preliminary Q1 G...</td>\n",
       "      <td>BULLETS</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>reuters</td>\n",
       "      <td>43881</td>\n",
       "      <td>Retail &amp; Consumer</td>\n",
       "      <td>Corona beer maker Constellation sees 2024 prof...</td>\n",
       "      <td>2023-04-06T12:59:00</td>\n",
       "      <td>April 6 (Reuters) - Constellation Brands Inc (...</td>\n",
       "      <td></td>\n",
       "      <td>NULL</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>reuters</td>\n",
       "      <td>43904</td>\n",
       "      <td>Mergers &amp; AcquisitionsMergers &amp; AcquisitionsDr...</td>\n",
       "      <td>BioNTech, DualityBio to develop cancer treatme...</td>\n",
       "      <td>2023-04-03T21:28:00</td>\n",
       "      <td>April 3 (Reuters) - Germany's BioNTech (22UAy....</td>\n",
       "      <td></td>\n",
       "      <td>NULL</td>\n",
       "      <td>303</td>\n",
       "      <td>0.708222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reuters</td>\n",
       "      <td>43912</td>\n",
       "      <td>CommentaryBy Rebecca ChristieBreakingviews</td>\n",
       "      <td>New EU debt rules have way to avoid past mistakes</td>\n",
       "      <td>2023-04-04T10:32:00</td>\n",
       "      <td>BRUSSELS, April 4 (Reuters Breakingviews) - Th...</td>\n",
       "      <td></td>\n",
       "      <td>NULL</td>\n",
       "      <td>236</td>\n",
       "      <td>0.126197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reuters</td>\n",
       "      <td>43916</td>\n",
       "      <td>CommentaryBy Rebecca ChristieBreakingviews</td>\n",
       "      <td>Rome foot-dragging can help EU kick bad aid ha...</td>\n",
       "      <td>2023-04-18T09:52:00</td>\n",
       "      <td>BRUSSELS, April 18 (Reuters Breakingviews) - I...</td>\n",
       "      <td></td>\n",
       "      <td>NULL</td>\n",
       "      <td>133</td>\n",
       "      <td>0.225602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    source     id                                           category  \\\n",
       "0  reuters  43869                                      Asian Markets   \n",
       "1  reuters  43881                                  Retail & Consumer   \n",
       "2  reuters  43904  Mergers & AcquisitionsMergers & AcquisitionsDr...   \n",
       "3  reuters  43912         CommentaryBy Rebecca ChristieBreakingviews   \n",
       "4  reuters  43916         CommentaryBy Rebecca ChristieBreakingviews   \n",
       "\n",
       "                                               title            published  \\\n",
       "0  Taiwan seen slipping into recession in Q1, Reu...  2023-04-26T04:54:00   \n",
       "1  Corona beer maker Constellation sees 2024 prof...  2023-04-06T12:59:00   \n",
       "2  BioNTech, DualityBio to develop cancer treatme...  2023-04-03T21:28:00   \n",
       "3  New EU debt rules have way to avoid past mistakes  2023-04-04T10:32:00   \n",
       "4  Rome foot-dragging can help EU kick bad aid ha...  2023-04-18T09:52:00   \n",
       "\n",
       "                                                body  \\\n",
       "0  TAIPEI, April 26 (Reuters) - Taiwan's export-d...   \n",
       "1  April 6 (Reuters) - Constellation Brands Inc (...   \n",
       "2  April 3 (Reuters) - Germany's BioNTech (22UAy....   \n",
       "3  BRUSSELS, April 4 (Reuters Breakingviews) - Th...   \n",
       "4  BRUSSELS, April 18 (Reuters Breakingviews) - I...   \n",
       "\n",
       "                                             summary summary_type  topic  \\\n",
       "0  * \\n* For poll data click:\\n* Preliminary Q1 G...      BULLETS     -1   \n",
       "1                                                            NULL     -1   \n",
       "2                                                            NULL    303   \n",
       "3                                                            NULL    236   \n",
       "4                                                            NULL    133   \n",
       "\n",
       "   probability  \n",
       "0     0.000000  \n",
       "1     0.000000  \n",
       "2     0.708222  \n",
       "3     0.126197  \n",
       "4     0.225602  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77c6d1da-768a-4677-9480-b1e63b4c1211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded correctly.\n",
      "Producing Shingles...\n",
      "Shingles produced in:\t 11.78 seconds.\n"
     ]
    }
   ],
   "source": [
    "#print(\"Loading dataset...\")\n",
    "#dataset=pd.read_csv(\"dataset_rent_rome_kijiji.tsv\", sep=\"\\t\")\n",
    "dataset['doc_id']=dataset.index\n",
    "doc_nr = dataset['doc_id'].max()\n",
    "\n",
    "print(\"Dataset loaded correctly.\")\n",
    "print(\"Producing Shingles...\")\n",
    "start_time = time.time()\n",
    "#an array where the index i represent the document_id and the element shingling_list[i] the hashed shingles for document document_id\n",
    "shingling_list = [None] * (doc_nr +1) \n",
    "shingling_size = 10\n",
    "signature_size = 50\n",
    "bands_nr = 10\n",
    "\n",
    "shingler_inst = shingler(shingling_size)\n",
    "signer = minhashSigner(signature_size)\n",
    "\n",
    "#produce hashed shinglings for all documents\n",
    "for index, row in dataset.iterrows():\n",
    "    doc = row['title']+\" \"+row['body']\n",
    "    i = row['doc_id']\n",
    "    \n",
    "    shinglings = shingler_inst.get_hashed_shingles( shingler_inst.get_shingles(doc) )\n",
    "    shingling_list[i] = shinglings\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Shingles produced in:\\t %.2f seconds.\"%(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f49d2b4-605a-4b19-aef8-2f20957c7a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing signature matrix...\n",
      "Signature Matrix computed in:\t 247.88 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Computing signature matrix...\")\n",
    "#produce a signature for each shingle set\n",
    "signature_matrix = signer.compute_signature_matrix( shingling_list )\n",
    "end_time = time.time()\n",
    "print(\"Signature Matrix computed in:\\t %.2f seconds.\" %(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87897054-bc5f-4c86-9b54-62dc9a35e462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing LSH similarity...\n",
      "LSH Similarity computed in:\t 0.25 seconds.\n",
      "Similar Elements Found: 43\n"
     ]
    }
   ],
   "source": [
    "lsh_instance = lsh(threshold=0.5)\n",
    "start_time = time.time()\n",
    "print(\"Computing LSH similarity...\")\n",
    "lsh_similar_itemset = lsh_instance.get_similar_items(signature_matrix, bands_nr, signature_size)\n",
    "end_time = time.time()\n",
    "lsh_computation_time = end_time - start_time\n",
    "print(\"LSH Similarity computed in:\\t %.2f seconds.\\nSimilar Elements Found: %d\" %(lsh_computation_time,len(lsh_similar_itemset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f07c5a7-b800-4e8e-9210-2ada467e22f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Create an empty graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes and edges to the graph based on document pairs\n",
    "for pair in lsh_similar_itemset:\n",
    "    for document in pair:\n",
    "        if not G.has_node(document):\n",
    "            G.add_node(document)\n",
    "    G.add_edge(pair[0], pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a4ba0f0-8f5c-4782-83cb-baec7e153841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create the graph (as in the previous example)\n",
    "G = nx.Graph()\n",
    "\n",
    "for pair in lsh_similar_itemset:\n",
    "    for document in pair:\n",
    "        if not G.has_node(document):\n",
    "            G.add_node(document)\n",
    "    G.add_edge(pair[0], pair[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27b481ad-9c98-4546-9822-63f98d37bff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print intial number of nodes and edges: \n",
      "Nodes:  73\n",
      "Edges:  38\n"
     ]
    }
   ],
   "source": [
    "print(\"Print intial number of nodes and edges: \")\n",
    "print(\"Nodes: \",len(G.nodes()))\n",
    "print(\"Edges: \",len(G.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4859cf03-e36e-4cd7-96af-aff8a6f21363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_nodes(graph):\n",
    "    nodes_to_remove = []\n",
    "    visited = set()\n",
    "    \n",
    "    for node in graph.nodes():\n",
    "        if node not in visited:\n",
    "            connected_component = list(nx.node_connected_component(graph, node))\n",
    "            if len(connected_component) > 1:\n",
    "                nodes_to_remove.extend(connected_component[1:])\n",
    "            visited.update(connected_component)\n",
    "    \n",
    "    graph.remove_nodes_from(nodes_to_remove)\n",
    "    \n",
    "    return nodes_to_remove\n",
    "\n",
    "# Remove duplicates from the graph and get the list of removed nodes\n",
    "removed_nodes = remove_duplicate_nodes(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd2db740-a3aa-442a-8074-3c8b4b60ab52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print the number of nodes and edges after removing duplicates: \n",
      "Nodes:  36\n",
      "Edges:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Print the number of nodes and edges after removing duplicates: \")\n",
    "print(\"Nodes: \",len(G.nodes()))\n",
    "print(\"Edges: \",len(G.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "82a9dc7b-a649-4a22-bd27-d3ec6937a113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6399, 11)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset[~dataset['doc_id'].isin(removed_nodes)]\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ac870a-ce09-4fc2-b4b2-c22163d3eb10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu110.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m108"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
