{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "660fc4b7-3437-4a56-af99-7c7547b5cff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topics</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Google, Microsoft, and OpenAI are all investin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Oil prices rise on China demand hopes, OPEC+ o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>TikTok is facing increasing scrutiny from gove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The Federal Reserve is expected to raise inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The US labor market is still strong, with job ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topics                                            summary\n",
       "0       0  Google, Microsoft, and OpenAI are all investin...\n",
       "1       1  Oil prices rise on China demand hopes, OPEC+ o...\n",
       "2       2  TikTok is facing increasing scrutiny from gove...\n",
       "3       3  The Federal Reserve is expected to raise inter...\n",
       "4       4  The US labor market is still strong, with job ..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "\n",
    "\n",
    "random.seed(93)\n",
    "np.random.seed(93)\n",
    "\n",
    "\n",
    "summarizer_type = \"vertex-ai\"\n",
    "\n",
    "\n",
    "topic_df = pd.read_parquet(\"gs://scraped-news-article-data-null/2023-topics-%s.parquet\" % summarizer_type)\n",
    "topic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba70ab30-a81f-4f71-b2b7-c613345e6b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Google, Microsoft, and OpenAI are all investin...\n",
       "1    Oil prices rise on China demand hopes, OPEC+ o...\n",
       "2    TikTok is facing increasing scrutiny from gove...\n",
       "3    The Federal Reserve is expected to raise inter...\n",
       "4    The US labor market is still strong, with job ...\n",
       "Name: summary, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_existing_sum = topic_df.loc[(topic_df.summary.str.len() > 0) & (topic_df.summary.str.lower().str.strip() != \"no theme\")]\n",
    "topic_existing_sum.summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39796166-e2fd-43cd-aa48-ee745078eaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PROMPT = \"A numbered list of summaries of topics from news articles is give below. \" +\\\n",
    "\"Using only information in the summaries, and without speculating, identify the topics from the list that can be further investigated to answer the inquiry below. \" +\\\n",
    "\"In addition, explain why the topics identified are selected. \" + \\\n",
    "'The answer should be formatted as:\\nRELEVANT TOPICS: 1(2/10), 5(6/10), 10(1/10)\\nREASON: reason for selecting topics 1, 5, 10\\nwhere 1, 5, and 10 are the selected topics from the list. (2/10) is the probability that topic 1 is relevant to the inquiry.\\n\\nInquiry: %s\\nList of Topics:\\n'\n",
    "\n",
    "\n",
    "def generate_topic_prompts(summary_df, inquiry, limiter, base_prompt=BASE_PROMPT):\n",
    "    start_idx = 0\n",
    "    end_idx = len(summary_df.index)\n",
    "    \n",
    "    row_format = \"%d. %s\\n\"\n",
    "    while start_idx < end_idx:\n",
    "        prompt = base_prompt % inquiry\n",
    "        current_idx = start_idx\n",
    "        while limiter(prompt) and current_idx < end_idx:\n",
    "            topic_id = summary_df.iloc[current_idx][\"topics\"]\n",
    "            topic_summary = summary_df.iloc[current_idx][\"summary\"]\n",
    "            prompt = prompt + row_format % (topic_id, topic_summary)\n",
    "            current_idx = current_idx + 1\n",
    "        start_idx = current_idx\n",
    "        yield prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6004edf-0dfb-4717-92cb-247e0d4d04b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.preview.language_models import TextGenerationModel\n",
    "import re\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    ")  # for exponential backoff\n",
    "import tiktoken\n",
    "\n",
    "\n",
    "\n",
    "def create_palm2_filter(prompt=BASE_PROMPT, temperature=0.7, max_new_tokens=1024, max_prompt_tokens=1024):\n",
    "    cache_dir = \"/home/jupyter/models\"\n",
    "    tokenizer = LlamaTokenizer.from_pretrained(\"/home/jupyter/koala_transformer\", device_map=\"auto\", cache_dir=cache_dir,  max_input_size=6656)\n",
    "    project_id = \"msca310019-capstone-f945\"\n",
    "    model_name = \"text-bison@001\"\n",
    "    location = \"us-central1\"\n",
    "    matcher = re.compile(r\"\\<SUMMARY\\>(?P<summary>.+)\\<\\/SUMMARY\\>\")\n",
    "    \n",
    "    \"\"\"Predict using a Large Language Model.\"\"\"\n",
    "    vertexai.init(project=project_id, location=location)\n",
    "    model = TextGenerationModel.from_pretrained(model_name)\n",
    "\n",
    "    @retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "    def predict_large_language_model_sample(\n",
    "        temperature: float,\n",
    "        max_decode_steps: int,\n",
    "        top_p: float,\n",
    "        top_k: int,\n",
    "        content: str,\n",
    "        ):\n",
    "        \n",
    "        response = model.predict(\n",
    "            content,\n",
    "            temperature=temperature,\n",
    "            max_output_tokens=max_decode_steps,\n",
    "            top_k=top_k,\n",
    "            top_p=top_p)\n",
    "        return response\n",
    "    \n",
    "    def token_count_limiter(prompt):\n",
    "        tokens = tokenizer(prompt, return_tensors=\"pt\")\n",
    "        token_count = tokens[\"input_ids\"].shape[1]\n",
    "        return token_count <= max_prompt_tokens\n",
    "    \n",
    "    def filter_topics(topic_df, inquiry):\n",
    "        \n",
    "        for p in generate_topic_prompts(topic_df, inquiry, token_count_limiter, base_prompt=prompt):\n",
    "            result = predict_large_language_model_sample(temperature=temperature, max_decode_steps=max_new_tokens, top_p=0.8, top_k=40, content=p)\n",
    "            result = str(result)\n",
    "            print(result)\n",
    "    \n",
    "    return filter_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f70887c8-1250-4f2f-be36-e33d77f9adee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import tiktoken\n",
    "\n",
    "\n",
    "with open(\"/home/jupyter/apikey\", \"r\") as api_fp:\n",
    "    api_key = api_fp.read().strip()\n",
    "    \n",
    "\n",
    "def create_openai_summarizer(api_key, prompt=BASE_PROMPT, temperature=0.7, max_new_tokens=1024, max_prompt_tokens=3000):\n",
    "    openai.api_key = api_key\n",
    "    engine = \"gpt-3.5-turbo\"\n",
    "    encoding = tiktoken.encoding_for_model(engine)\n",
    "    matcher = re.compile(r\"SUMMARY:(?P<summary>(.|\\n)+)EXPLANATION\")\n",
    "    \n",
    "    @retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "    def completion_with_backoff(**kwargs):\n",
    "        return openai.ChatCompletion.create(**kwargs)\n",
    "    \n",
    "    def token_count_limiter(prompt):\n",
    "        tokens = encoding.encode(prompt)\n",
    "        return len(tokens) <= max_prompt_tokens\n",
    "    \n",
    "    def filter_topics(topic_df, inquiry):\n",
    "        \n",
    "        for p in generate_topic_prompts(topic_df, inquiry, token_count_limiter, base_prompt=prompt):\n",
    "            messages=[\n",
    "                {'role': 'user', 'content': p},\n",
    "            ]\n",
    "            result = completion_with_backoff(messages=messages, model=engine, temperature=temperature, max_tokens=max_new_tokens)\n",
    "            result_text = result['choices'][0]['message']['content']\n",
    "            print(result_text)\n",
    "            \n",
    "    return filter_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3e0724a-bb8a-4057-8790-5e8575966534",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_llm = create_openai_summarizer(api_key, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5064ef28-c677-444b-9cb3-09f2683ee95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RELEVANT TOPICS: 0(8/10), 59(6/10)\n",
      "REASON: Topic 0 discusses companies investing heavily in AI, which is directly related to the inquiry. Topic 59 discusses AI startup funding, which could provide information on which companies are making progress in AI.\n",
      "RELEVANT TOPICS: 98(4/10), 109(2/10)\n",
      "REASON: Intel's changes may indicate progress on AI, Novo Nordisk's obesity drug may involve AI technology\n"
     ]
    }
   ],
   "source": [
    "filter_llm(topic_existing_sum, \"Which companies are making progress on AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ec9c953-5a1d-4df9-9f93-3ddc92cfb1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def create_koala_topic_summarizer(prompt=BASE_PROMPT, temperature=0.7, max_new_tokens=512, max_prompt_tokens=1536):\n",
    "    cache_dir = \"/home/jupyter/models\"\n",
    "    tokenizer = LlamaTokenizer.from_pretrained(\"/home/jupyter/koala_transformer\", device_map=\"auto\", cache_dir=cache_dir,  max_input_size=2048)\n",
    "    model = LlamaForCausalLM.from_pretrained(\"/home/jupyter/koala_transformer\", torch_dtype=torch.float16, low_cpu_mem_usage=True, device_map=\"auto\", cache_dir=cache_dir)\n",
    "    \n",
    "    def generate_koala_prompt(prompt):\n",
    "        system = \"\"\"BEGINNING OF CONVERSATION: \"\"\"\n",
    "        template = system + \"USER: %s GPT:\"\n",
    "        return template % prompt\n",
    "    \n",
    "    def generate_from_tokens(tokens):\n",
    "        outputs = model.generate(**tokens,\n",
    "                             do_sample=True, \n",
    "                             top_p=1.0,\n",
    "                             temperature=temperature,\n",
    "                             max_new_tokens=max_new_tokens)\n",
    "        result = tokenizer.decode(outputs[0][tokens[\"input_ids\"].shape[1]:], skip_special_tokens=True)\n",
    "        return \"\".join(result)\n",
    "    \n",
    "    def token_count_limiter(final_prompt):\n",
    "        final_prompt = generate_koala_prompt(final_prompt)\n",
    "        tokens = tokenizer(final_prompt, return_tensors=\"pt\")\n",
    "        token_count = tokens[\"input_ids\"].shape[1]\n",
    "        return token_count <= max_prompt_tokens\n",
    "    \n",
    "    def filter_topics(topic_df, inquiry):\n",
    "        \n",
    "        for p in generate_topic_prompts(topic_df, inquiry, token_count_limiter, base_prompt=prompt):\n",
    "            final_prompt = generate_koala_prompt(p)\n",
    "            tokens = tokenizer(final_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "            print(generate_from_tokens(tokens))\n",
    "    \n",
    "    return filter_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "007f80f1-4955-498c-9566-269255402c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e90ff514324f4b168ec7ad95fcffc7ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filter_koala = create_koala_topic_summarizer(temperature=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfdf591-1e84-4dd4-b728-0af27e158d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RELEVANT TOPICS: 1, 5, 10\n",
      "\n",
      "REASON:\n",
      "\n",
      "1.   The topic of the first article is the performance of the FTSE 100, which is a stock market index of the 100 largest companies listed on the London Stock Exchange. The index is a good indicator of the overall health of the UK economy, and the articles discuss the performance of the index and the companies listed on it.\n",
      "2.   The topic of the second article is the performance of the FTSE 100, which is a stock market index of the 100 largest companies listed on the London Stock Exchange. The index is a good indicator of the overall health of the UK economy, and the articles discuss the performance of the index and the companies listed on it.\n",
      "3.   The topic of the third article is the performance of the FTSE 100, which is a stock market index of the 100 largest companies listed on the London Stock Exchange. The index is a good indicator of the overall health of the UK economy, and the articles discuss the performance of the index and the companies listed on it.\n",
      "4.   The topic of the fourth article is the performance of the FTSE 100, which is a stock market index of the 100 largest companies listed on the London Stock Exchange. The index is a good indicator of the overall health of the UK economy, and the articles discuss the performance of the index and the companies listed on it.\n",
      "5.   The topic of the fifth article is the performance of the FTSE 100, which is a stock market index of the 100 largest companies listed on the London Stock Exchange. The index is a good indicator of the overall health of the UK economy, and the articles discuss the performance of the index and the companies listed on it.\n",
      "6.   The topic of the sixth article is the performance of the FTSE 100, which is a stock market index of the 100 largest companies listed on the London Stock Exchange. The index is a good indicator of the overall health of the UK economy, and the articles discuss the performance of the index and the companies listed on it.\n",
      "7.   The topic of the seventh article is the performance of the FTSE 100, which is a stock market index of the 100 largest companies\n",
      "RELEVANT TOPICS: 1, 5, 10\n",
      "\n",
      "REASON:\n",
      "\n",
      "1.   The inquiry is about companies making progress on AI, and the list of topics includes companies that are involved in AI research and development.\n",
      "2.   The list of topics includes a mix of economic and financial news, as well as news about companies and industries that are affected by the current economic climate.\n",
      "3.   The list of topics includes a mix of international and domestic news, which can provide a broad perspective on the current economic climate.\n",
      "4.   The list of topics includes a mix of positive and negative news, which can provide a balanced view of the current economic climate.\n",
      "5.   The list of topics includes a mix of short-term and long-term news, which can provide a mix of near-term and long-term perspectives on the current economic climate.\n",
      "6.   The list of topics includes a mix of news about different industries and countries, which can provide a mix of regional and global perspectives on the current economic climate.\n",
      "7.   The list of topics includes a mix of news about different types of companies, which can provide a mix of large and small company perspectives on the current economic climate.\n",
      "8.   The list of topics includes a mix of news about different types of industries, which can provide a mix of manufacturing, service, and technology perspectives on the current economic climate.\n",
      "9.   The list of topics includes a mix of news about different types of countries, which can provide a mix of developed and developing country perspectives on the current economic climate.\n",
      "10.   The list of topics includes a mix of news about different types of economic indicators, which can provide a mix of short-term and long-term perspectives on the current economic climate.\n",
      "\n",
      "Therefore, the topics identified are relevant to the inquiry because they provide a mix of economic and financial news, as well as news about companies and industries that are affected by the current economic climate.\n",
      "RELEVANT TOPICS:\n",
      "\n",
      "1.   Montana governor signs bill banning transgender medical care for youths.\n",
      "2.   The theme of the titles is the Russian oil price cap.\n",
      "3.   Inquiry: Which companies are making progress on AI?\n",
      "4.   REASON: reason for selecting topics from the list.\n",
      "\n",
      "1.   The topic of the list is the number of the list.\n",
      "2.   The list of topics is the list of topics from the list.\n",
      "3.   The list of topics is the list of topics from the list.\n",
      "4.   The list of topics is the list of topics from the list.\n",
      "5.   The list of topics is the list of topics from the list.\n",
      "6.   The list of topics is the list of topics from the list.\n",
      "7.   The list of topics from the list.\n",
      "8.   The list of topics from the list of topics from the list of topics from the list of topics from the list of topics from the list of topics from the list of topics from the list of topics from the list of topics from the list of topics from the list of topics from the list of topics from the topics from the list of topics from the list of topics from the list of topics from the list of topics from the list of topics from the topics from the list of topics from the list of topics from the list of topics from the list of topics from the topics from the list of topics from the list of topics from the topics from the list of topics from the list of topics from the topics from the topics from the topics from the topics from the topics from the topics from the list of topics from the list of topics from the topics from the topics from the topics from the topics from the topics from the topics from the topics from the topics from the topics from the topics from the topics from the topics from the topics from the topics from the topics from the topics from the topics from the topics from the topics from the topics from the topics from the topics from the topics from the topics from the topics from the topics from the topics from the topics from the topics from the topics from topics from topics from the topics from topics, and topics, and topics from topics from the topics from the topics from the topics from the topics from the topics from the topics from the topics, the topics from the topics from the topics from the topics from the topics from the topics from the topics from the topics from\n",
      "RELEVANT TOPICS: 1, 5, 10\n",
      "\n",
      "REASON:\n",
      "\n",
      "1.   The articles discuss various topics related to the global economy, including the ongoing war in Ukraine, rising inflation, and concerns about the global economy. These topics can be used to answer questions about the global economy and its future prospects.\n",
      "2.   The articles discuss various topics related to the global economy, including the ongoing war in Ukraine, rising inflation, and concerns about the global economy. These topics can be used to answer questions about the global economy and its future prospects.\n",
      "3.   The articles discuss various topics related to the global economy, including the ongoing war in Ukraine, rising inflation, and concerns about the global economy. These topics can be used to answer questions about the global economy and its future prospects.\n",
      "\n",
      "RELEVANT TOPICS: 1, 5, 10\n",
      "\n",
      "REASON:\n",
      "\n",
      "1.   The articles discuss various topics related to the global economy, including the ongoing war in Ukraine, rising inflation, and concerns about the global economy. These topics can be used to answer questions about the global economy and its future prospects.\n",
      "2.   The articles discuss various topics related to the global economy, including the ongoing war in Ukraine, rising inflation, and concerns about the global economy. These topics can be used to answer questions about the global economy and its future prospects.\n",
      "3.   The articles discuss various topics related to the global economy, including the ongoing war in Ukraine, rising inflation, and concerns about the global economy. These topics can be used to answer questions about the global economy and its future prospects.\n"
     ]
    }
   ],
   "source": [
    "filter_koala(topic_existing_sum, \"Which companies are making progress on AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4b4e8d-0c98-4815-af33-c11be696656f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "llamaidx",
   "name": "common-cu110.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m108"
  },
  "kernelspec": {
   "display_name": "llamaidx",
   "language": "python",
   "name": "llamaidx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
