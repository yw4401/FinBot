{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-10T22:19:41.442377Z",
     "start_time": "2023-11-10T22:19:40.541809Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from langchain.llms import OpenAI, VertexAI\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['question', 'answer', 'references'],\n    num_rows: 43579\n})"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_qa = load_dataset(\"THUDM/webglm-qa\", split=\"train\")\n",
    "web_qa"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-10T22:19:43.195690Z",
     "start_time": "2023-11-10T22:19:41.854009Z"
    }
   },
   "id": "d71c7d5bc5d95bbd"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "prompt = (\"You are a helpful AI assistant that will decide which of the given questions would \"\n",
    "          \"likely be asked by a retail investor doing research on possible investment opportunities. \"\n",
    "          \"Respond with the question numbers of the likely asked questions. DO NOT respond with the question itself.\\n\"\n",
    "          \"Example:\\n\\n\"\n",
    "          \"1. Why does the Earth orbit the sun?\\n\"\n",
    "          \"2. Which companies are making AI products?\\n\"\n",
    "          \"3. How does protein shakes affect muscle growth?\\n\"\n",
    "          \"4. How is Microsoft generating revenue via AI?\\n\"\n",
    "          \"5. Does NEM faces legal risks with their new mining developments?\\n\"\n",
    "          \"6. Who invented the telescope?\\n\"\n",
    "          \"7. Where is New York City Located?\\n\"\n",
    "          \"8. How was Wells Fargo impacted in terms of business by the recent leak incident?\\n\"\n",
    "          \"9. Why did Paypal stock crash?\\n\"\n",
    "          \"10. When is the next olympic occurring?\\n\\n\"\n",
    "          \"2, 4, 5, 8, 9\\n\\n{format_instructions}\\n\\n\"\n",
    "          \"Follow the example for the following list of questions:\\n{questions}\")\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "with open(\"../key\") as fp:\n",
    "    key = fp.read().strip()\n",
    "\n",
    "plan_llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", openai_api_key=key,\n",
    "                  temperature=0, max_tokens=512)\n",
    "prompt = PromptTemplate.from_template(prompt).partial(format_instructions=output_parser.get_format_instructions())\n",
    "chain = prompt | plan_llm | output_parser"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-10T22:19:43.912717Z",
     "start_time": "2023-11-10T22:19:43.870550Z"
    }
   },
   "id": "4c1900dd249f8d16"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "['4']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_questions(questions):\n",
    "    template = \"{num}. {question}\"\n",
    "    result = []\n",
    "    for i, q in enumerate(questions):\n",
    "        result.append(template.format(num=i, question=q))\n",
    "    return \"\\n\".join(result)\n",
    "\n",
    "\n",
    "chain.invoke({\n",
    "    \"questions\": [\"in football whats the point of wasting the first two plays with a rush - up the middle - not regular rush plays i get those\", \"Why are different tiers (regular < mid < premium) of gas' prices almost always 10 cents different?\", \"Why do you see weird colors when you press your eyes?\", \"Which oil and gas companies are developing new oil fields?\"]\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-10T22:19:45.442201Z",
     "start_time": "2023-11-10T22:19:45.025521Z"
    }
   },
   "id": "88418080fcf0c289"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/43579 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dd97cc4462cd42c3986ad0c9949c963c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def decide_relevance(batch):\n",
    "    questions = format_questions(batch[\"question\"])\n",
    "    relevant = [False for _ in batch[\"question\"]]\n",
    "    try:\n",
    "        result = chain.invoke({\"questions\": questions})\n",
    "        for r in result:\n",
    "            relevant[int(r)] = True\n",
    "    except:\n",
    "        pass\n",
    "    return {\"relevant\": relevant}\n",
    "\n",
    "\n",
    "web_qa = web_qa.map(decide_relevance, batched=True, batch_size=10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-10T23:18:14.839829Z",
     "start_time": "2023-11-10T22:19:46.403965Z"
    }
   },
   "id": "24af3c2edb46eb9b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta: 14802\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/28777 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ff15b36464154f0faa3482ad3f30d46f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "web_qa_filtered = web_qa.filter(lambda batch: batch[\"relevant\"], batched=True)\n",
    "delta = 100\n",
    "prev_len = len(web_qa)\n",
    "while prev_len - len(web_qa_filtered) >= delta:\n",
    "    print(\"Delta: \" + str(prev_len - len(web_qa_filtered)))\n",
    "    prev_len = len(web_qa_filtered)\n",
    "    web_qa_filtered = web_qa_filtered.map(decide_relevance, batched=True, batch_size=10)\n",
    "    web_qa_filtered = web_qa_filtered.filter(lambda batch: batch[\"relevant\"], batched=True)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-11-10T23:22:52.342434Z"
    }
   },
   "id": "a2e089d5869015b0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f279994ef344eb2b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
