{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c14bbfef-8969-4537-be73-85a2767cfe11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import GPTVectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.llm_predictor import HuggingFaceLLMPredictor\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from IPython.display import Markdown, display\n",
    "from llama_index import ServiceContext, LangchainEmbedding\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "237a9e34-d785-4d8b-aa7a-b3d4e21eb38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/envs/llamaidx/lib/python3.10/site-packages (from sentence_transformers) (4.29.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/llamaidx/lib/python3.10/site-packages (from sentence_transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/envs/llamaidx/lib/python3.10/site-packages (from sentence_transformers) (1.13.1+cu116)\n",
      "Requirement already satisfied: torchvision in /opt/conda/envs/llamaidx/lib/python3.10/site-packages (from sentence_transformers) (0.14.1+cu116)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/llamaidx/lib/python3.10/site-packages (from sentence_transformers) (1.24.3)\n",
      "Collecting scikit-learn (from sentence_transformers)\n",
      "  Downloading scikit_learn-1.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting scipy (from sentence_transformers)\n",
      "  Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nltk in /opt/conda/envs/llamaidx/lib/python3.10/site-packages (from sentence_transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/envs/llamaidx/lib/python3.10/site-packages (from sentence_transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/envs/llamaidx/lib/python3.10/site-packages (from sentence_transformers) (0.14.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/llamaidx/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.12.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/envs/llamaidx/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.5.0)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/llamaidx/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.29.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/llamaidx/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/llamaidx/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/envs/llamaidx/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/envs/llamaidx/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.5.5)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/envs/llamaidx/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.3)\n",
      "Requirement already satisfied: click in /opt/conda/envs/llamaidx/lib/python3.10/site-packages (from nltk->sentence_transformers) (8.1.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/envs/llamaidx/lib/python3.10/site-packages (from nltk->sentence_transformers) (1.2.0)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn->sentence_transformers)\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/envs/llamaidx/lib/python3.10/site-packages (from torchvision->sentence_transformers) (9.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/llamaidx/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/llamaidx/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/llamaidx/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/llamaidx/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.5.7)\n",
      "Building wheels for collected packages: sentence_transformers\n",
      "  Building wheel for sentence_transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125926 sha256=d9462ab4f49c6fdbc5b40887482d92d8ad209e85c948f7188e71124edc7d955e\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
      "Successfully built sentence_transformers\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn, sentence_transformers\n",
      "Successfully installed scikit-learn-1.2.2 scipy-1.10.1 sentence_transformers-2.2.2 threadpoolctl-3.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%pip install torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu116\n",
    "#%pip install transformers datasets evaluate rouge-score py7zr\n",
    "#%pip install nltk\n",
    "#%pip install accelerate\n",
    "#%pip install sentencepiece\n",
    "#%pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bdc7f47-80e8-4c37-be68-fb747412d13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74dd783b-3ac7-456b-870c-6733fb25d332",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../test data/sample_articles\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eabc367c-8758-41cf-aafe-5c7551a8a4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.prompts.prompts import SimpleInputPrompt\n",
    "\n",
    "system_prompt = \"\"\"<|SYSTEM|># StableLM Tuned (Alpha version)\n",
    "- StableLM is a helpful and harmless open-source AI language model developed by StabilityAI.\n",
    "- StableLM is excited to be able to help the user, but will refuse to do anything that could be considered harmful to the user.\n",
    "- StableLM is more than just an information source, StableLM is also able to write poetry, short stories, and make jokes.\n",
    "- StableLM will refuse to participate in anything that could harm a human.\n",
    "\"\"\" \n",
    "\n",
    "# This will wrap the default prompts that are internal to llama-index\n",
    "query_wrapper_prompt = SimpleInputPrompt(\"<|USER|>{query_str}<|ASSISTANT|>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1c43d53-6316-4bd9-b0c3-b60c57b98745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15e8d51aa2c54de4a10e55a6f3731a76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "hf_predictor = HuggingFaceLLMPredictor(\n",
    "    max_input_size=4096, \n",
    "    max_new_tokens=2048,\n",
    "    temperature=0,\n",
    "    do_sample=False,\n",
    "    system_prompt=system_prompt,\n",
    "    query_wrapper_prompt=query_wrapper_prompt,\n",
    "    tokenizer_name=\"stabilityai/stablelm-tuned-alpha-7b\",\n",
    "    model_name=\"stabilityai/stablelm-tuned-alpha-7b\",\n",
    "    device_map=\"auto\",\n",
    "    stopping_ids=[50278, 50279, 50277, 1, 0],\n",
    "    tokenizer_kwargs={\"max_length\": 4096},\n",
    "    # uncomment this if using CUDA to reduce memory usage\n",
    "    model_kwargs={\"torch_dtype\": torch.float16}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f060602-568a-4e47-bda2-8c6e14bd8dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b516b582470b400784970796ca4db555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)a8e1d/.gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d84c0d1ad540dea8deb217849df7a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "895b54f0223b4b96afeef7dd18277360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)b20bca8e1d/README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ee62d2c8e4e4840961e2ec39c5fb8ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)0bca8e1d/config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2939c879507147d1b979ffd51ade3223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a79413fa840b4e94b0083a3cf858e91d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)e1d/data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "507361b5f3f14a18be5ac7579526736c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ec5b4a2a1148cb9d3741b278753bc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c65a816d7f94660a9564c23cf6fb0ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7635bba25ccc47a790c73c68c9759282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)a8e1d/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d601bb9b914549c080d6fa08da3080d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c460f16f7c3a4ee6a0c3161e3781ea77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)8e1d/train_script.py:   0%|          | 0.00/13.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e57ede947524c21893c28b7797cdca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)b20bca8e1d/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "453bd573a11c4322a8a3ce0a2434b06e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)bca8e1d/modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device: cuda\n",
      "Use pytorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "embed_model = LangchainEmbedding(HuggingFaceEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6a14330-aa17-4374-adf1-e7e8a48abf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_context = ServiceContext.from_defaults(chunk_size_limit=1024, llm_predictor=hf_predictor, embed_model=embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "525866cf-4781-4556-b8e3-58dd2e02de2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1667f6b5178d44af958e4923434dfa3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81108aa0304d4445996fca354d91e0ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9523b686d6648cf8cdb50f804ae05fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 16174 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 16174 tokens\n"
     ]
    }
   ],
   "source": [
    "documents = SimpleDirectoryReader(data_dir).load_data()\n",
    "new_index = GPTVectorStoreIndex.from_documents(documents, service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99afeeae-c80a-43e0-b254-c9c17c2c31b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f6c83943dd34cc7a62170ddcdf97acf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 11 tokens\n",
      "> [retrieve] Total embedding token usage: 11 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 2151 tokens\n",
      "> [get_response] Total LLM token usage: 2151 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    }
   ],
   "source": [
    "query_engine = new_index.as_query_engine()\n",
    "response = query_engine.query(\"Which companies made drugs to help alzheimer disease?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fec76177-1a58-4cc8-8cff-e019b04951d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The companies that made drugs to help Alzheimer's are Eli Lilly, J.J. Abrams, and Biogen.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470463d9-1118-4998-8511-c80563f01a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "llamaidx",
   "name": "common-cu110.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m108"
  },
  "kernelspec": {
   "display_name": "llamaidx",
   "language": "python",
   "name": "llamaidx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
