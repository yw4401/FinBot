{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sentence_transformers as st\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "TRAIN_QUESTION_PATH = \"gs://scraped-news-article-data-null/fiqa-augmented-trainq.parquet\"\n",
    "TRAIN_DOC_PATH = \"gs://scraped-news-article-data-null/fiqa-augmented-traindoc.parquet\"\n",
    "TRAIN_REL_PATH = \"gs://scraped-news-article-data-null/fiqa-augmented-trainrel.parquet\"\n",
    "EVAL_QUESTION_PATH = \"gs://scraped-news-article-data-null/fiqa-augmented-devq.parquet\"\n",
    "EVAL_DOC_PATH = \"gs://scraped-news-article-data-null/fiqa-augmented-devdoc.parquet\"\n",
    "EVAL_REL_PATH = \"gs://scraped-news-article-data-null/fiqa-augmented-devrel.parquet\"\n",
    "TEST_QUESTION_PATH = \"gs://scraped-news-article-data-null/fiqa-augmented-testq.parquet\"\n",
    "TEST_DOC_PATH = \"gs://scraped-news-article-data-null/fiqa-augmented-testdoc.parquet\"\n",
    "TEST_REL_PATH = \"gs://scraped-news-article-data-null/fiqa-augmented-testrel.parquet\"\n",
    "\n",
    "BASE_MODEL = \"thenlper/gte-base\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   query_id  doc_id  relevance\n0         0   18850        1.0\n1         4  196463        1.0\n2         5   69306        1.0\n3         6  560251        1.0\n4         6  188530        1.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>query_id</th>\n      <th>doc_id</th>\n      <th>relevance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>18850</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>196463</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>69306</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>560251</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>188530</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_q = pd.read_parquet(TRAIN_QUESTION_PATH)\n",
    "train_doc = pd.read_parquet(TRAIN_DOC_PATH)\n",
    "train_rel = pd.read_parquet(TRAIN_REL_PATH)\n",
    "train_rel.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "   query_id  doc_id  relevance\n0         8  566392        1.0\n1         8   65404        1.0\n2        15  325273        1.0\n3        18   88124        1.0\n4        26  285255        1.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>query_id</th>\n      <th>doc_id</th>\n      <th>relevance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8</td>\n      <td>566392</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8</td>\n      <td>65404</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>15</td>\n      <td>325273</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>18</td>\n      <td>88124</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>26</td>\n      <td>285255</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_q = pd.read_parquet(TEST_QUESTION_PATH)\n",
    "test_doc = pd.read_parquet(TEST_DOC_PATH)\n",
    "test_rel = pd.read_parquet(TEST_REL_PATH)\n",
    "test_rel.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<InputExample> label: 1, texts: What is considered a business expense on a business trip?; The IRS Guidance pertaining to the subject.  In general the best I can say is your business expense may be deductible.  But it depends on the circumstances and what it is you want to deduct. Travel Taxpayers who travel away from home on business may deduct related   expenses, including the cost of reaching their destination, the cost   of lodging and meals and other ordinary and necessary expenses.   Taxpayers are considered “traveling away from home” if their duties   require them to be away from home substantially longer than an   ordinary day’s work and they need to sleep or rest to meet the demands   of their work. The actual cost of meals and incidental expenses may be   deducted or the taxpayer may use a standard meal allowance and reduced   record keeping requirements. Regardless of the method used, meal   deductions are generally limited to 50 percent as stated earlier.    Only actual costs for lodging may be claimed as an expense and   receipts must be kept for documentation. Expenses must be reasonable   and appropriate; deductions for extravagant expenses are not   allowable. More information is available in Publication 463, Travel,   Entertainment, Gift, and Car Expenses. Entertainment Expenses for entertaining clients, customers or employees may be   deducted if they are both ordinary and necessary and meet one of the   following tests: Directly-related test: The main purpose of the entertainment activity is the conduct of business, business was actually conducted   during the activity and the taxpayer had more than a general   expectation of getting income or some other specific business benefit   at some future time.   Associated test: The entertainment was associated with the active conduct of the taxpayer’s trade or business and occurred directly   before or after a substantial business discussion. Publication 463 provides more extensive explanation of these tests as   well as other limitations and requirements for deducting entertainment   expenses. Gifts Taxpayers may deduct some or all of the cost of gifts given in the   course of their trade or business. In general, the deduction is   limited to $25 for gifts given directly or indirectly to any one   person during the tax year. More discussion of the rules and   limitations can be found in Publication 463. If your LLC reimburses you for expenses outside of this guidance it should be treated as Income for tax purposes. Edit for Meal Expenses: Amount of standard meal allowance.   The standard meal allowance is   the federal M&IE rate. For travel in 2010, the rate for most small   localities in the United States is $46 a day. Source IRS P463 Alternately you could reimburse at a per diem rate\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers.evaluation import InformationRetrievalEvaluator\n",
    "\n",
    "\n",
    "def to_input_examples(questions, documents, relations):\n",
    "    positives = pd.merge(left=questions, right=relations, on=\"query_id\")\n",
    "    positives = pd.merge(left=positives, right=documents, on=\"doc_id\")\n",
    "    for _, row in positives.iterrows():\n",
    "        yield st.InputExample(texts=[row[\"query_text\"], row[\"doc_text\"]], label=1)\n",
    "\n",
    "\n",
    "def to_retrieval_evaluator(questions, documents, relations, **kwargs):\n",
    "    q_dict = {}\n",
    "    doc_dict = {}\n",
    "    rel_dict = {}\n",
    "    for _, row in questions.iterrows():\n",
    "        q_dict[str(row[\"query_id\"])] = row[\"query_text\"]\n",
    "    for _, row in documents.iterrows():\n",
    "        doc_dict[str(row[\"doc_id\"])] = row[\"doc_text\"]\n",
    "    relations = relations.copy()\n",
    "    relations[\"doc_id_list\"] = relations.doc_id.apply(lambda x: [str(x)])\n",
    "    relations_grouped = relations[[\"query_id\", \"doc_id_list\"]].groupby(\"query_id\").sum().reset_index()\n",
    "    for _, row in relations_grouped.iterrows():\n",
    "        rel_dict[str(row[\"query_id\"])] = set(row[\"doc_id_list\"])\n",
    "    return InformationRetrievalEvaluator(queries=q_dict, corpus=doc_dict, relevant_docs=rel_dict, **kwargs)\n",
    "\n",
    "for i in to_input_examples(train_q, train_doc, train_rel):\n",
    "    print(i)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "Batches:   0%|          | 0/21 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8d59bdc76228439bacf3daa040e9bce3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:15<00:00, 15.13s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": "     accuracy@k  precision@k  recall@k    ndcg@k     mrr@k     map@k\n1      0.695988     0.695988  0.187505  0.695988  0.695988       NaN\n3      0.807099     0.584362  0.440857  0.663874  0.744084       NaN\n5      0.851852     0.473765  0.552121  0.652049  0.754347       NaN\n10     0.890432     0.311728  0.660335  0.658487  0.759256       NaN\n100         NaN          NaN       NaN       NaN       NaN  0.600996",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy@k</th>\n      <th>precision@k</th>\n      <th>recall@k</th>\n      <th>ndcg@k</th>\n      <th>mrr@k</th>\n      <th>map@k</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.695988</td>\n      <td>0.695988</td>\n      <td>0.187505</td>\n      <td>0.695988</td>\n      <td>0.695988</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.807099</td>\n      <td>0.584362</td>\n      <td>0.440857</td>\n      <td>0.663874</td>\n      <td>0.744084</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.851852</td>\n      <td>0.473765</td>\n      <td>0.552121</td>\n      <td>0.652049</td>\n      <td>0.754347</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.890432</td>\n      <td>0.311728</td>\n      <td>0.660335</td>\n      <td>0.658487</td>\n      <td>0.759256</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>100</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.600996</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_evaluator = to_retrieval_evaluator(test_q, test_doc, test_rel,\n",
    "                                            show_progress_bar=True, ndcg_at_k=[1, 3, 5, 10], mrr_at_k=[1, 3, 5, 10])\n",
    "base_model = st.SentenceTransformer(model_name_or_path=BASE_MODEL)\n",
    "pd.DataFrame(test_set_evaluator.compute_metrices(model=base_model)['cos_sim'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
