{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acc39e3f-6e1e-474a-98f0-85b11779ae9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topics</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The news articles revolve around the advanceme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The news articles cover the fluctuations in oi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The news articles revolve around the security ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The Federal Reserve's interest rate decisions ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The news articles cover various aspects of the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topics                                            summary\n",
       "0       0  The news articles revolve around the advanceme...\n",
       "1       1  The news articles cover the fluctuations in oi...\n",
       "2       2  The news articles revolve around the security ...\n",
       "3       3  The Federal Reserve's interest rate decisions ...\n",
       "4       4  The news articles cover various aspects of the..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "summarizer_type = \"openai\"\n",
    "\n",
    "\n",
    "topic_df = pd.read_parquet(\"gs://scraped-news-article-data-null/2023-topics-%s.parquet\" % summarizer_type)\n",
    "topic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8579aaf8-3dcc-4f1b-b15a-74d7c4e4e7ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    The news articles revolve around the advanceme...\n",
       "1    The news articles cover the fluctuations in oi...\n",
       "2    The news articles revolve around the security ...\n",
       "3    The Federal Reserve's interest rate decisions ...\n",
       "4    The news articles cover various aspects of the...\n",
       "Name: summary, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_existing_sum = topic_df.loc[(topic_df.summary.str.len() > 0) & (topic_df.summary.str.lower().str.strip() != \"no theme\")]\n",
    "topic_existing_sum = topic_existing_sum.loc[topic_existing_sum.topics <= 300]\n",
    "topic_existing_sum.summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef5441f9-4271-4555-9e14-bf8bd6dc671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from summarizer.topic_sum import create_topic_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59adcde0-5a38-4f21-b102-2484d0d03508",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/jupyter/apikey\", \"r\") as api_fp:\n",
    "    api_key = api_fp.read().strip()\n",
    "\n",
    "\n",
    "filter_llm = create_topic_filter(api_key=api_key, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49ff12b5-4dea-44aa-8cfc-1e4b3cba2eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d1a03530fe54addbb122e92a46e33b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index import GPTVectorStoreIndex, SimpleDirectoryReader, LLMPredictor, PromptHelper\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "from llama_index.llm_predictor import HuggingFaceLLMPredictor\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from IPython.display import Markdown, display\n",
    "from llama_index import ServiceContext, LangchainEmbedding\n",
    "import os\n",
    "import pandas as pd\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "import torch\n",
    "from llama_index.prompts.prompts import SimpleInputPrompt\n",
    "from langchain.llms.base import LLM\n",
    "from typing import Optional, List, Mapping, Any\n",
    "\n",
    "\n",
    "system_prompt = \"\"\"BEGINNING OF CONVERSATION: \"\"\" \n",
    "# This will wrap the default prompts that are internal to llama-index\n",
    "query_wrapper_prompt = SimpleInputPrompt(\"USER: {query_str} GPT:\")\n",
    "query_wrapper_prompt.format(query_str=\"test\")\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"/home/jupyter/koala_transformer\", device_map=\"auto\", max_input_size=2048)\n",
    "model = LlamaForCausalLM.from_pretrained(\"/home/jupyter/koala_transformer\", torch_dtype=torch.float16, device_map=\"auto\", cache_dir=\"/home/jupyter/data/transformers\")\n",
    "\n",
    "\n",
    "class CustomLLM(LLM):\n",
    "\n",
    "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
    "        prompt = query_wrapper_prompt.format(query_str=prompt)\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "        outputs = model.generate(**inputs, max_new_tokens=1024, \n",
    "                             do_sample=False, \n",
    "                             temperature=0)\n",
    "        result = tokenizer.batch_decode(outputs, skip_special_tokens=True, spaces_between_special_tokens=False)[0]\n",
    "        # only return newly generated tokens\n",
    "        return result[len(prompt):]\n",
    "\n",
    "    @property\n",
    "    def _identifying_params(self) -> Mapping[str, Any]:\n",
    "        return {\"name_of_model\": \"Koala\"}\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"llama\"\n",
    "\n",
    "    \n",
    "# define our LLM\n",
    "num_output = 512\n",
    "max_chunk_overlap = 20\n",
    "llm_predictor = LLMPredictor(llm=CustomLLM())\n",
    "\n",
    "\n",
    "prompt_helper = PromptHelper(max_input_size=2048, num_output=num_output, max_chunk_overlap=max_chunk_overlap)\n",
    "hf_predictor = LLMPredictor(llm=CustomLLM())\n",
    "embed_model = LangchainEmbedding(HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\"))\n",
    "service_context = ServiceContext.from_defaults(chunk_size_limit=512, llm_predictor=hf_predictor, embed_model=embed_model, prompt_helper=prompt_helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5f51750-29d6-4110-9098-d83dd08efc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import load_index_from_storage, load_indices_from_storage, load_graph_from_storage\n",
    "from llama_index.storage.docstore import SimpleDocumentStore\n",
    "from llama_index.vector_stores import SimpleVectorStore\n",
    "from llama_index.storage.index_store import SimpleIndexStore\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "persist_dir_base = \"/home/jupyter/topic_indices\"\n",
    "\n",
    "\n",
    "def create_llama_index_lazyloader(directory=persist_dir_base):\n",
    "    index_dict = {}\n",
    "    \n",
    "    def get_llama_index(topic_number):\n",
    "        if topic_number not in index_dict:\n",
    "            topic_index_dir = Path(directory, str(topic_number))\n",
    "            storage_context = StorageContext.from_defaults(\n",
    "                docstore=SimpleDocumentStore.from_persist_dir(persist_dir=topic_index_dir),\n",
    "                vector_store=SimpleVectorStore.from_persist_dir(persist_dir=topic_index_dir),\n",
    "                index_store=SimpleIndexStore.from_persist_dir(persist_dir=topic_index_dir),\n",
    "            )\n",
    "            index = load_index_from_storage(storage_context=storage_context, service_context=service_context)\n",
    "            index_dict[topic_number] = index\n",
    "        return index_dict[topic_number]\n",
    "            \n",
    "    return get_llama_index\n",
    "        \n",
    "lazy_loader = create_llama_index_lazyloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1a4e835-974f-458c-9bf8-5f57f8597c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified relevant topic #: 0\n",
      " The recent launch of Google's Bard and Microsoft's Bing chat have brought more tech giants into the generative AI space, with half of the companies surveyed by ResumeBuilder using OpenAI's ChatGPT. The post-pandemic job market has also led to the adoption of AI products, with companies like OpenAI and Stability AI participating in a public evaluation of their AI systems. However, the United States regulators have fallen short of European governments in crafting strong rules on deepfakes and misinformation. The President Joe Biden administration has also released an AI Bill of Rights and a risk management plan for AI use.\n",
      "Identified relevant topic #: 59\n",
      " The report on the progress of artificial intelligence companies is a mix of positive and negative news. On the positive side, several companies have raised significant funding and are making progress in developing enterprise applications. For example, Adept, a startup that focuses on training a neural network to perform general tasks for enterprise clients, has raised $65 million in a Series B funding round led by General Catalyst and Spark Capital. Additionally, several high-population states such as Texas, New York, and Florida have punched well above their weight in terms of AI-related hiring.\n",
      "\n",
      "On the negative side, the report mentions that academic collaboration in AI research is dwarfed by private industry research. The United States and China continue to lead in collaborative research, but the relationship has slowed in 2021. Additionally, some companies have experienced management reshuffles, such as Adept, which recently experienced some management reshuffles when co-founders Niki Parmar and Ashish Vaswani left the company.\n",
      "\n",
      "Overall, the report suggests that while there is significant progress being made in the field of artificial intelligence, there are still challenges to overcome, such as the need for more collaboration between academia and private industry.\n",
      "Identified relevant topic #: 98\n",
      " INSUFFICIENT INFORMATION. The provided information does not provide enough context or details about the companies making progress on artificial intelligence. The news articles mention several companies, including Micron Technology, but do not provide any specific information about their progress on AI.\n",
      "Identified relevant topic #: 114\n",
      " The news article provides information about the value of Reddit's data for artificial intelligence chatbots and the potential for Reddit to monetize its data through new revenue streams. The article also mentions that other companies, such as Twitter, are exploring similar strategies. However, the article does not provide enough information to answer the inquiry of which companies are making progress on artificial intelligence.\n",
      "Identified relevant topic #: 115\n",
      " INSUFFICIENT INFORMATION\n",
      "\n",
      "The provided information does not provide enough context or details to answer the inquiry. The article mentions that VinFast plans to start the trial production in 2024 as originally planned, but it does not provide any information about the progress of artificial intelligence in the company. The article also mentions that VinFast filed for an initial public offering in the U.S. but it does not provide any information about the progress of artificial intelligence in the company.\n",
      "Identified relevant topic #: 143\n",
      " INSUFFICIENT INFORMATION\n",
      "\n",
      "The provided extracts do not provide sufficient information to answer the inquiry. The extracts do not mention any specific companies that are making progress on artificial intelligence in the renewable energy industry. The extracts also do not provide any information about the use of AI in the industry or the level of progress that has been made.\n",
      "Identified relevant topic #: 169\n",
      " INSUFFICIENT INFORMATION. The news article does not provide enough information to answer the inquiry. The article mentions that Uber Technologies (UBER.N) will introduce electric vehicles (EVs) in India for ride-sharing, but it does not provide any details about the progress of other companies in the field of artificial intelligence.\n",
      "Identified relevant topic #: 193\n",
      " INSUFFICIENT INFORMATION\n",
      "\n",
      "The provided information does not provide enough context or details about the companies making progress on artificial intelligence. It does not mention any specific companies or their products or services related to artificial intelligence. Therefore, it is not possible to answer the given inquiry.\n",
      "Identified relevant topic #: 212\n",
      " INSUFFICIENT INFORMATION\n",
      "\n",
      "The provided information does not provide enough information to answer the inquiry. The news articles mention that Apple Inc has invested in India and plans to assemble iPhones and other products in the country, but they do not provide any information about the progress of artificial intelligence companies in India.\n",
      "Identified relevant topic #: 236\n",
      " INSUFFICIENT INFORMATION\n",
      "\n",
      "The provided information does not provide enough context or details to answer the inquiry. The news articles mention that the US government has added several companies to its economic blacklist over allegations of human rights abuses and other acts of oppression, but they do not specify which companies these are or what the allegations are. Additionally, the articles do not provide any information about the technology war between the US and China, or the tensions between the two countries.\n",
      "Identified relevant topic #: 299\n",
      " INSUFFICIENT INFORMATION\n",
      "\n",
      "The provided extracts do not provide enough information to answer the inquiry. The extracts do not mention any specific companies that are making progress on artificial intelligence. The extracts do not provide any information about the progress of artificial intelligence in general. The extracts do not provide any information about the regulatory authority or oversight of artificial intelligence development. The extracts do not provide any information about the text-based chatbot developed by OpenAI's that can draft prose, poetry or even computer code on command. The extracts do not provide any information about the text-based chatbot developed by OpenAI's that can draft prose, poetry or even computer code on command. The extracts do not provide any information about the text-based chatbot developed by OpenAI's that can draft prose, poetry or even computer code on command. The extracts do not provide any information about the text-based chatbot developed by OpenAI's that can draft prose, poetry or even computer code on command. The extracts do not provide any information about the text-based chatbot developed by OpenAI's that can draft prose, poetry or even computer code on command. The extracts do not provide any information about the text-based chatbot developed by OpenAI's that can draft prose, poetry or even computer code on command. The extracts do not provide any information about the text-based chatbot developed by OpenAI's that can draft prose, poetry or even computer code on command. The extracts do not provide any information about the text-based chatbot developed by OpenAI's that can draft prose, poetry or even computer code on command. The extracts do not provide any information about the text-based chatbot developed by OpenAI's that can draft prose, poetry or even computer code on command. The extracts do not provide any information about the text-based chatbot developed by OpenAI's that can draft prose, poetry or even computer code on command. The extracts do not provide any information about the text-based chatbot developed by OpenAI's that can draft prose, poetry or even computer code on command. The extracts do not provide any information about the text-based chatbot developed by OpenAI's that can draft prose, poetry or even computer code on command. The extracts do not provide any information about the text-based chatbot developed by OpenAI's that can draft prose, poetry or even computer code on command. The extracts do not provide any information about the text-based chatbot developed by OpenAI's that can draft prose, poetry or even computer code on command. The extracts do not provide any information about the text-based chatbot developed by OpenAI's that can draft prose, poetry or even computer code on command. The extracts do not provide any information about the text-based chatbot developed by OpenAI's that can draft prose, poetry or even computer code on command. The extracts do not provide any information about the text-based chatbot developed by OpenAI's that can draft prose, poetry or even computer code on command. The extracts do not provide any information about the text-based chatbot developed by OpenAI's that can draft prose, poetry or even computer code on command. The extracts do not provide any information about the text-based chatbot developed by OpenAI's that can draft prose, poetry or even computer code on command. The extracts do not provide any information about the text-based chatbot developed by OpenAI's that can draft prose, poetry or even computer code on command. The extracts do not provide any information about the text-based chatbot developed by OpenAI's that can draft prose, poetry or even computer code on command. The extracts do not provide any information about the text-based chatbot developed by OpenAI's that can draft prose, poetry or even computer code on command. The extracts do not provide any information about the text-based chatbot developed by OpenAI's that can draft prose, poetry or even computer code on command. The extracts do not provide any information about the text-based chatbot developed by OpenAI's that can draft prose, poetry or even computer code on command. The extracts do not provide any information about the text-based chatbot developed by OpenAI's that can draft prose, poetry or even computer code on command. The extracts do not provide any information about the text-based chatbot developed by OpenAI's that can draft prose, poetry or even computer code on command. The extracts do not provide any information about the text-based chatbot developed by OpenAI's that can draft prose, poetry or even computer code\n"
     ]
    }
   ],
   "source": [
    "from llama_index import QuestionAnswerPrompt\n",
    "\n",
    "\n",
    "inquiry = \"Which companies are making progress on artifical intelligence?\"\n",
    "\n",
    "\n",
    "PROMPT = \"Several extracts from news articles are provided below. \" + \\\n",
    "\"Using only information from the news extracts, write a well written report with a headline that can answer the given inquiry. \" + \\\n",
    "'If the extracts do not contain sufficient information to answer the inquiry, write \"INSUFFICIENT INFORMATION\".\\n\\n' + \\\n",
    "\"Inquiry: {query_str}\\n\\nNews Article Extracts:\\n{context_str}\\n\"\n",
    "QA_PROMPT = QuestionAnswerPrompt(PROMPT)\n",
    "\n",
    "\n",
    "\n",
    "for r in filter_llm(topic_existing_sum, \"Which companies are making progress on artifical intelligence?\"):\n",
    "    if r.rating < 0.5:\n",
    "        continue\n",
    "    print(\"Identified relevant topic #: \" + r.topic_number)\n",
    "    index = lazy_loader(r.topic_number)\n",
    "    query_engine = index.as_query_engine(text_qa_template=QA_PROMPT)\n",
    "    print(query_engine.query(inquiry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c5a79f-db73-42bb-9f28-eae22445dbb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "llamaidx",
   "name": "common-cu110.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m108"
  },
  "kernelspec": {
   "display_name": "llamaidx",
   "language": "python",
   "name": "llamaidx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
